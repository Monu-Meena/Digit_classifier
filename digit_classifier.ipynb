{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "digit_classifier",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMfbaZisdCIpRb3PCmox2BL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Monu-Meena/Digit_classifier/blob/master/digit_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7YRJeGOJ7Sj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import sys\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from skimage.transform import rotate\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MLzCs-NN2tP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Using GPU\n",
        "print(sys.version)\n",
        "device = 'cuda'\n",
        "#Checking for GPU\n",
        "print(torch.version.cuda)\n",
        "print(torch.cuda.device_count())\n",
        "print(torch.cuda.is_available())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4rtHYXTN-AG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = \"/content/drive/My Drive/Colab Notebooks/Mnist_dataset/\"\n",
        "\n",
        "df = pd.read_csv(path + 'train.csv')\n",
        "train = torch.from_numpy(df.values)\n",
        "x_train = (train[:, 1:])#.to(device)\n",
        "y_train = (train[:, 0])#.to(device)\n",
        "del train, df\n",
        "\n",
        "\n",
        "df = pd.read_csv(path + 'test.csv')\n",
        "x_test = torch.from_numpy(df.values)#.to(device)\n",
        "print(x_test.shape, y_train.shape, x_train.shape, y_train.max())\n",
        "\n",
        "n, c = x_train.shape #n=no. of training egs & c=n_H *n_W for each eg\n",
        "print(n, c)\n",
        "print(x_train.shape, y_train.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sgXkzK6N-SK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_seed = 1\n",
        "\n",
        "x_train, x_cv, y_train, y_cv = train_test_split(x_train, y_train, test_size = 0.1, random_state = random_seed)\n",
        "n_train, _ = x_train.shape\n",
        "n_cv, _ = x_cv.shape\n",
        "print(n_train, n_cv)\n",
        "x_train#.to(device)\n",
        "y_train#.to(device)\n",
        "x_cv#.to(device)\n",
        "y_cv#.to(device)\n",
        "print(x_train.shape, y_train.shape, x_cv.shape, y_cv.shape, x_train.dtype, y_train.dtype)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmZwjyMJOvA_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_temp = x_train.cpu().numpy().astype(np.float32)\n",
        "print(x_train_temp.shape, x_train_temp.dtype)\n",
        "\n",
        "final_train_x = []\n",
        "final_train_y = []\n",
        "for i in range(x_train.shape[0]):\n",
        "    final_train_x.append(x_train_temp[i])\n",
        "    final_train_x.append(rotate(x_train_temp[i].reshape((28, 28)), angle=20, mode = 'wrap').reshape((784)))\n",
        "    final_train_x.append(rotate(x_train_temp[i].reshape((28, 28)), angle=10, mode = 'wrap').reshape((784)))\n",
        "    final_train_x.append(rotate(x_train_temp[i].reshape((28, 28)), angle=-20, mode = 'wrap').reshape((784)))\n",
        "    final_train_x.append(rotate(x_train_temp[i].reshape((28, 28)), angle=-10, mode = 'wrap').reshape((784)))\n",
        "    for j in range(5):\n",
        "        final_train_y.append(y_train[i].cpu().numpy().reshape(1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sB--6NgdOvOU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "final_train_x = np.reshape(final_train_x, (len(final_train_x), 28*28))\n",
        "final_train_y = np.reshape(final_train_y, (-1))\n",
        "\n",
        "print(final_train_x[0].dtype, final_train_y[0].dtype)\n",
        "\n",
        "random_seed = 1\n",
        "x_train = torch.from_numpy(np.array(final_train_x)).to(device)\n",
        "y_train = torch.from_numpy(np.array(final_train_y)).squeeze().to(device)\n",
        "\n",
        "print(x_train.shape, y_train.shape, x_cv.shape, y_cv.shape, x_train.dtype, y_train.dtype)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxxF_eT8OvaA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index = 5\n",
        "plt.imshow(x_train[index].cpu().reshape((28, 28)), cmap='gray')\n",
        "print (y_train[index])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XoG5rjZO7tv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index = 5\n",
        "plt.imshow(x_cv[index].cpu().reshape((28, 28)), cmap='gray')\n",
        "print (y_cv[index])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKzGUT86O723",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "train_ds = TensorDataset(x_train, y_train)\n",
        "valid_ds = TensorDataset(x_cv, y_cv)\n",
        "\n",
        "def get_data(train_ds, bs):\n",
        "    return DataLoader(train_ds, batch_size =bs, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEISToj_O79K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(x, y):\n",
        "  x = x/255.0\n",
        "  return x.reshape(-1, 1, 28, 28).to(device), y.to(device)\n",
        "\n",
        "\n",
        "class WrappedDataLoader:\n",
        "    def __init__(self, dl, func):\n",
        "        self.dl = dl\n",
        "        self.func = func\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dl)\n",
        "\n",
        "    def __iter__(self):\n",
        "        batches = iter(self.dl)\n",
        "        for b in batches:\n",
        "            yield (self.func(*b))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-H8vUXbPE9P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class Mnist_CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2) \n",
        "    self.conv2 = nn.Conv2d(32, 48, kernel_size=5, stride=2, padding=2) \n",
        "    self.conv3 = nn.Conv2d(48, 64, kernel_size=3, stride=1, padding=1) \n",
        "    self.conv4 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1) \n",
        "    self.lin1 = nn.Linear(3136, 256)\n",
        "    self.lin2 = nn.Linear(256, 10)\n",
        "    self.norm1 = nn.BatchNorm2d(32)\n",
        "    self.norm2 = nn.BatchNorm2d(48)\n",
        "    self.norm3 = nn.BatchNorm2d(64)\n",
        "    self.drop1 = nn.Dropout2d(p=0.4)\n",
        "    self.drop2 = nn.Dropout2d(p=0.4)\n",
        "    self.norm4 = nn.BatchNorm1d(256)\n",
        "    self.drop3 = nn.Dropout(p=0.4)\n",
        "    #self.lin2 = nn.Linear(128, 10)\n",
        "    \n",
        "\n",
        "\n",
        "  def forward(self, xb):\n",
        "    xb = xb.view(-1, 1, 28, 28)\n",
        "    #1\n",
        "    xb = F.relu(self.conv1(xb))\n",
        "    xb = self.norm1(xb)\n",
        "    #xb = F.avg_pool2d(xb, 2, 2)\n",
        "    \n",
        "    #2\n",
        "    xb = F.relu(self.conv2(xb))\n",
        "    xb = self.norm2(xb)\n",
        "    #xb = F.avg_pool2d(xb, 2, 2)\n",
        "    xb = self.drop2(xb)\n",
        "    \n",
        "    #3\n",
        "    xb = F.relu(self.conv3(xb))\n",
        "    xb = self.norm3(xb)\n",
        "    \n",
        "    #4\n",
        "    xb = F.relu(self.conv4(xb))\n",
        "    xb = self.norm3(xb)\n",
        "    xb = F.avg_pool2d(xb, 2, 2)\n",
        "    xb = self.drop2(xb)\n",
        "    \n",
        "    #fc1\n",
        "    xb = torch.flatten(xb, 1, 3)\n",
        "    xb = F.relu(self.lin1(xb))\n",
        "    xb = self.norm4(xb)\n",
        "    xb = self.drop3(xb)\n",
        "    \n",
        "    #fc2\n",
        "    xb = self.lin2(xb)\n",
        "    return xb.view(-1, xb.size(1))\n",
        "\n",
        "loss_func = F.cross_entropy \n",
        "model = Mnist_CNN()\n",
        "model.float()\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfwHVSmNPFGb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(out, yb):\n",
        "    pred = torch.argmax(out, keepdim= False, dim=1)\n",
        "    return (pred == yb).float().mean() \n",
        "'''for using negative log likelihood loss and log softmax activation,\n",
        "Pytorch provides a single function F.cross_entropy that combines the two'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P27r2SOwPFQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(model, epochs, train_dl, valid_dl, opt):\n",
        "    losses = []\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        train_loss =0\n",
        "        train_acc =0\n",
        "        model.train()\n",
        "        for xb, yb in train_dl:\n",
        "            xb.to(device)\n",
        "            yb.to(device)\n",
        "            pred = model(xb.float())\n",
        "            pred.to(device)\n",
        "            train_acc += accuracy(pred, yb)\n",
        "            loss = loss_func(pred, yb)\n",
        "            train_loss += loss\n",
        "            #back propogation\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()      \n",
        "\n",
        "        losses.append(train_loss)\n",
        "        print(\"Iteration no: \"+ str(epoch), \"loss = \"+str(losses[epoch].item()))\n",
        "        print(\"Accuracy of train set:\", train_acc/len(train_dl))\n",
        "        lr_scheduler.step(train_loss/len(train_dl))\n",
        "        \n",
        "        \n",
        "        model.eval()    \n",
        "        with torch.no_grad():\n",
        "            valid_acc=0\n",
        "            loss_valid = 0\n",
        "            for xb_valid, yb_valid in valid_dl:\n",
        "                xb_valid.to(device)\n",
        "                yb_valid.to(device)\n",
        "                pred_valid = model(xb_valid.float())\n",
        "                pred_valid.to(device)\n",
        "                valid_acc += accuracy(pred_valid, yb_valid)\n",
        "                loss_valid += loss_func(pred_valid, yb_valid)\n",
        "            print(\"Accuracy of validation set :\", valid_acc/len(valid_dl))\n",
        "\n",
        "    plt.plot(losses)\n",
        "    plt.ylabel(\"loss\")\n",
        "    plt.xlabel(\"iterations (per hundreds)\")\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lt7k4s0_PUU-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl = get_data(train_ds, bs=64)\n",
        "valid_dl = get_data(valid_ds, bs = 128)\n",
        "train_dl = WrappedDataLoader(train_dl, preprocess)\n",
        "valid_dl = WrappedDataLoader(valid_dl, preprocess)\n",
        "\n",
        "opt = optim.Adam(model.parameters(), lr=0.01)\n",
        "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, patience=1, verbose=True, eps = 10e-10)\n",
        "\n",
        "fit(model, 160, train_dl, valid_dl, opt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jye1KHn5PUgM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Deleting some variables of no use later to free some space\n",
        "del train_dl, valid_dl, x_train, y_train, x_cv, y_cv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HwH54bqPg71",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test = x_test/255.0\n",
        "x_test = x_test.reshape(-1, 1, 28, 28)\n",
        "with torch.no_grad():\n",
        "    x_test = x_test    #Passing the entire test set to the GPU\n",
        "    test_out = model(x_test.float()).cpu()\n",
        "    test_pred = torch.argmax(test_out, dim = 1, keepdim=True).cpu().numpy()\n",
        "    #test_pred_np = test_pred.cpu().numpy() \n",
        "    test_pred = np.reshape(test_pred, test_pred.shape[0])\n",
        "    print(test_pred.shape)\n",
        "    \n",
        "    row1 = pd.Series(test_pred, name=\"Label\")\n",
        "    row2 = pd.Series(range(1, 28001), name=\"ImageId\")\n",
        "    submission = pd.concat([row2, row1], axis=1)\n",
        "    submission.to_csv(\"cnn_mnist_datagen.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1wURkZvPhFT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_accuracy(model):\n",
        "    print(\"Accuracy of train set:\", accuracy(model(x_train.float()), y_train))\n",
        "    print(\"Accuracy of test set:\", accuracy(model(x_cv.float()), y_cv))\n",
        "\n",
        "print_accuracy(model)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}